# Проект для «Викишоп»

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.

Построенная модель должна быть со значением метрики качества *F1* не меньше 0.75. 

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.


## Навыки и инструменты

- **python**
- **pandas**
- **numpy**
- **torch**
- **transformers**
- **wordcloud**
- **nltk**
- **re**
- **catboost**
- sklearn.model_selection.**cross_val_score**
- sklearn.metrics.**f1_score**
- sklearn.linear_model.**LogisticRegression**
- **matplotlib**

## 

## Общий вывод

Решили задачу определения токсичности комментариев.    
Подготовили данные и использовали модель BERT.    
С помощью BERT получили эмбеддинги.     
Для решения задачи классификации применили LogisticRegression и CatBoostClassifier.    
В качестве метрики выбрали F1.     
CatBoostClassifier показал лучший результат.     
На тесте получили 0.925
